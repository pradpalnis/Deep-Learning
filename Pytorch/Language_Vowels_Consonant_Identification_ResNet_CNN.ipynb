{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TaimQTuD2Kf7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#For converting the dataset to torchvision dataset format\n",
    "class VowelConsonantDataset(Dataset):\n",
    "    def __init__(self, file_path,train=True,transform=None):\n",
    "        self.transform = transform\n",
    "        self.file_path=file_path\n",
    "        self.train=train\n",
    "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
    "        self.len = len(self.file_names)\n",
    "        if self.train:\n",
    "            self.classes_mapping=self.get_classes()\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_name=self.file_names[index]\n",
    "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "        if self.train:\n",
    "            file_name_splitted=file_name.split(\"_\")\n",
    "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
    "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
    "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
    "            z1[Y1-10],z2[Y2]=1,1\n",
    "            label=torch.stack([z1,z2])\n",
    "\n",
    "            return image_data, label\n",
    "\n",
    "        else:\n",
    "            return image_data, file_name\n",
    "          \n",
    "    def pil_loader(self,path):\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "\n",
    "      \n",
    "    def get_classes(self):\n",
    "        classes=[]\n",
    "        for name in self.file_names:\n",
    "            name_splitted=name.split(\"_\")\n",
    "            classes.extend([name_splitted[0],name_splitted[1]])\n",
    "        classes=list(set(classes))\n",
    "        classes_mapping={}\n",
    "        for i,cl in enumerate(sorted(classes)):\n",
    "            classes_mapping[cl]=i\n",
    "        return classes_mapping\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gdBlULQPyax"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6_3MoD_P6LH"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89-Aq-yFP8RW"
   },
   "outputs": [],
   "source": [
    "full_data = VowelConsonantDataset(\"../input/train/train\",train=True,transform=transform)\n",
    "train_size = int(0.9 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "\n",
    "train_data, validation_data = random_split(full_data, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=60, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=60, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wsUnEsiP-WW"
   },
   "outputs": [],
   "source": [
    "test_data = VowelConsonantDataset(\"../input/test/test\",train=False,transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=60,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFw3UqAN37lo"
   },
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19025,
     "status": "ok",
     "timestamp": 1559370845983,
     "user": {
      "displayName": "Pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-mjoXd3R8m9o/AAAAAAAAAAI/AAAAAAAAAHQ/Az8ompGKKo8/s64/photo.jpg",
      "userId": "14719477536417352759"
     },
     "user_tz": -330
    },
    "id": "1Xd8Ee7s3htc",
    "outputId": "826503f8-8e40-4299-f038-789f5b5a0faf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /tmp/.torch/models/resnet18-5c106cde.pth\n",
      "46827520it [00:13, 3545414.30it/s]\n"
     ]
    }
   ],
   "source": [
    "resnet_vocab = models.resnet18(pretrained=True)\n",
    "resnet_const = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5DF1jWf30tc"
   },
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAhqxw254X8L"
   },
   "outputs": [],
   "source": [
    "for param in resnet_vocab.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in resnet_const.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1559371039815,
     "user": {
      "displayName": "Pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-mjoXd3R8m9o/AAAAAAAAAAI/AAAAAAAAAHQ/Az8ompGKKo8/s64/photo.jpg",
      "userId": "14719477536417352759"
     },
     "user_tz": -330
    },
    "id": "7ezwW8hK1tGp",
    "outputId": "1081043c-3a96-4bae-b31c-72d88989b92e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  4.5793e-41, -3.3615e-26,\n",
       "          4.5793e-41, -1.4979e-24,  4.5793e-41,  1.4013e-45,  6.9001e-07],\n",
       "        [ 0.0000e+00,  0.0000e+00,  2.1159e+23,  4.1765e-08,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTKSz3Et4dgS"
   },
   "outputs": [],
   "source": [
    "in_features = resnet_vocab.fc.in_features\n",
    "resnet_vocab.fc = nn.Linear(in_features,10)\n",
    "\n",
    "in_features = resnet_const.fc.in_features\n",
    "resnet_const.fc = nn.Linear(in_features,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1292,
     "status": "ok",
     "timestamp": 1559371068170,
     "user": {
      "displayName": "Pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-mjoXd3R8m9o/AAAAAAAAAAI/AAAAAAAAAHQ/Az8ompGKKo8/s64/photo.jpg",
      "userId": "14719477536417352759"
     },
     "user_tz": -330
    },
    "id": "gPztaAAS4gCS",
    "outputId": "3243cb0f-2f3a-4a6a-dace-9e6cbcaca70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in resnet_vocab.parameters():\n",
    "    if param.requires_grad:\n",
    "        print(param.shape)\n",
    "\n",
    "for param in resnet_const.parameters():\n",
    "    if param.requires_grad:\n",
    "        print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1172,
     "status": "ok",
     "timestamp": 1559371072544,
     "user": {
      "displayName": "Pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-mjoXd3R8m9o/AAAAAAAAAAI/AAAAAAAAAHQ/Az8ompGKKo8/s64/photo.jpg",
      "userId": "14719477536417352759"
     },
     "user_tz": -330
    },
    "id": "7J213-hI4wtf",
    "outputId": "f18e78cb-7363-49b1-988e-e82328742989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjmuwCFn4ldJ"
   },
   "outputs": [],
   "source": [
    "resnet_vocab = resnet_vocab.to(device)\n",
    "resnet_const = resnet_const.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#loss_fn = nn.BCELoss()\n",
    "#loss_fn = nn.BCEWithLogitsLoss()\n",
    "opt_vocab = optim.SGD(resnet_vocab.parameters(), lr=0.01)\n",
    "opt_const = optim.SGD(resnet_const.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awtHtdCB_1CV"
   },
   "outputs": [],
   "source": [
    "batch_size = 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veSAPzwODssP"
   },
   "outputs": [],
   "source": [
    "vocab_idx = torch.LongTensor([0])\n",
    "const_idx = torch.LongTensor([1])\n",
    "\n",
    "def evaluation(dataloader, model):\n",
    "    total_vocab, total_const, correct_vocab, correct_const  = 0, 0, 0 , 0\n",
    "    for data in dataloader:\n",
    "        inputs_vocab, labels_vocab = data\n",
    "        inputs_const, labels_const = data\n",
    "        labels_vocab = labels_vocab.index_select(1, vocab_idx).to(dtype=torch.long).squeeze()\n",
    "        labels_const = labels_const.index_select(1, const_idx).to(dtype=torch.long).squeeze()\n",
    "        labels_vocab = torch.argmax(labels_vocab, 1)\n",
    "        labels_const = torch.argmax(labels_const, 1)\n",
    "        inputs_vocab,inputs_const,labels_vocab,labels_const = inputs_vocab.to(device),inputs_const.to(device),labels_vocab.to(device),labels_const.to(device)\n",
    "        \n",
    "        outputs_vocab = model(inputs_vocab)\n",
    "        outputs_const = model(inputs_const)\n",
    "        _, pred_vocab = torch.max(outputs_vocab.data, 1)\n",
    "        _, pred_const = torch.max(outputs_const.data, 1)\n",
    "        total_vocab += labels_vocab.size(0)\n",
    "        total_const += labels_const.size(0)\n",
    "        correct_vocab += (pred_vocab == labels_vocab).sum().item()\n",
    "        correct_const += (pred_const == labels_const).sum().item()\n",
    "    return 100 * (correct_vocab + correct_const) / (total_vocab + total_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26436,
     "status": "ok",
     "timestamp": 1559371282408,
     "user": {
      "displayName": "Pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-mjoXd3R8m9o/AAAAAAAAAAI/AAAAAAAAAHQ/Az8ompGKKo8/s64/photo.jpg",
      "userId": "14719477536417352759"
     },
     "user_tz": -330
    },
    "id": "wgqyrFoRjTID",
    "outputId": "4db48d30-5b7b-40bb-f72a-b9787ac1d6ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss 4.71\n",
      "Iteration: 0/834, Loss: 4.71\n",
      "Min loss 4.63\n",
      "Min loss 4.62\n",
      "Min loss 4.61\n",
      "Min loss 4.58\n",
      "Min loss 4.56\n",
      "Min loss 4.56\n",
      "Iteration: 100/834, Loss: 4.60\n",
      "Min loss 4.54\n",
      "Epoch: 0/1, Test acc: 12.55, Train acc: 11.84\n",
      "Epoch: 0/1, Test acc: 10.20, Train acc: 11.94\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_epoch_arr = []\n",
    "max_epochs = 1\n",
    "\n",
    "min_loss = 1000\n",
    "\n",
    "n_iters = np.ceil(50000/batch_size)\n",
    "\n",
    "vocab_idx = torch.LongTensor([0])\n",
    "const_idx = torch.LongTensor([1])\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        inputs_vocab, labels_vocab = data\n",
    "        inputs_const, labels_const = data\n",
    "        labels_vocab = labels_vocab.index_select(1, vocab_idx).to(dtype=torch.long).squeeze()\n",
    "        labels_const = labels_const.index_select(1, const_idx).to(dtype=torch.long).squeeze()\n",
    "        labels_vocab = torch.argmax(labels_vocab, 1)\n",
    "        labels_const = torch.argmax(labels_const, 1)\n",
    "        inputs_vocab,inputs_const,labels_vocab,labels_const = inputs_vocab.to(device),inputs_const.to(device),labels_vocab.to(device),labels_const.to(device)\n",
    "        \n",
    "        opt_vocab.zero_grad()\n",
    "        opt_const.zero_grad()\n",
    "\n",
    "        outputs_vocab = resnet_vocab(inputs_vocab)\n",
    "        outputs_const = resnet_const(inputs_const)\n",
    "        loss_vocab = loss_fn(torch.sigmoid(outputs_vocab), labels_vocab)\n",
    "        loss_const = loss_fn(torch.sigmoid(outputs_const), labels_const)\n",
    "        loss = loss_vocab + loss_const\n",
    "        loss.backward()\n",
    "        opt_vocab.step()\n",
    "        opt_const.step()\n",
    "        \n",
    "        \n",
    "        if min_loss > loss.item():\n",
    "            min_loss = loss.item()\n",
    "            best_model_vocab = copy.deepcopy(resnet_vocab.state_dict())\n",
    "            best_model_const= copy.deepcopy(resnet_const.state_dict())\n",
    "            print('Min loss %0.2f' % min_loss)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Iteration: %d/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n",
    "            \n",
    "        del inputs_vocab, inputs_const, labels_vocab,labels_const,outputs_vocab,outputs_const\n",
    "        #torch.cuda.empty_cache()\n",
    "        \n",
    "    loss_epoch_arr.append(loss.item())\n",
    "        \n",
    "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n",
    "        epoch, max_epochs, \n",
    "        evaluation(validation_loader, resnet_vocab), evaluation(train_loader, resnet_vocab)))\n",
    "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n",
    "        epoch, max_epochs, \n",
    "        evaluation(validation_loader, resnet_const), evaluation(train_loader, resnet_const)))\n",
    "    \n",
    "    \n",
    "plt.plot(loss_epoch_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1559373392634,
     "user": {
      "displayName": "Pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-mjoXd3R8m9o/AAAAAAAAAAI/AAAAAAAAAHQ/Az8ompGKKo8/s64/photo.jpg",
      "userId": "14719477536417352759"
     },
     "user_tz": -330
    },
    "id": "MwF32HQ74u0r",
    "outputId": "2d68a00d-803e-4788-aa85-6cf35ea99a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'V0', 1: 'V1', 2: 'V2', 3: 'V3', 4: 'V4', 5: 'V5', 6: 'V6', 7: 'V7', 8: 'V8', 9: 'V9'} {0: 'C0', 1: 'C1', 2: 'C2', 3: 'C3', 4: 'C4', 5: 'C5', 6: 'C6', 7: 'C7', 8: 'C8', 9: 'C9'}\n"
     ]
    }
   ],
   "source": [
    "dict_vocab = {0:'V0',1:'V1',2:'V2',3:'V3',4:'V4',5:'V5',6:'V6',7:'V7',8:'V8',9:'V9'}\n",
    "dict_const = {0:'C0',1:'C1',2:'C2',3:'C3',4:'C4',5:'C5',6:'C6',7:'C7',8:'C8',9:'C9'}\n",
    "print(dict_vocab,dict_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0bOxmBJ4DkX"
   },
   "outputs": [],
   "source": [
    "image_List = []\n",
    "class_List = []\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "  images, labels = data\n",
    "  images = images.to(device)\n",
    "  results_vocab = resnet_vocab(images)\n",
    "  results_const = resnet_const(images)\n",
    "  _, predicted_vocab = torch.max(results_vocab, 1)\n",
    "  _, predicted_const = torch.max(results_const, 1)\n",
    "  \n",
    "  predicted_vocab = list(map(lambda x : dict_vocab[int(x)], predicted_vocab))\n",
    "  predicted_const = list(map(lambda x : dict_const[int(x)], predicted_const))\n",
    "  for label, vocab, const in zip(labels, predicted_vocab, predicted_const):\n",
    "    predict_class = vocab +'_'+ const\n",
    "    image_List.append(label)\n",
    "    class_List.append(predict_class)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzlXnVTB81Wd"
   },
   "outputs": [],
   "source": [
    "submission = {}\n",
    "submission['ImageId'] = image_List\n",
    "submission['Class'] = class_List\n",
    "submission = pd.DataFrame(submission)\n",
    "submission = submission[['ImageId', 'Class']]\n",
    "submission = submission.sort_values(['ImageId'])\n",
    "submission.to_csv(\"submisision.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1559374678981,
     "user": {
      "displayName": "Pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-mjoXd3R8m9o/AAAAAAAAAAI/AAAAAAAAAHQ/Az8ompGKKo8/s64/photo.jpg",
      "userId": "14719477536417352759"
     },
     "user_tz": -330
    },
    "id": "DHOHrVejz3cX",
    "outputId": "6ce1eb54-b417-441d-dfd4-a8db2265c325"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1.png</td>\n",
       "      <td>V5_C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>10.png</td>\n",
       "      <td>V9_C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8865</th>\n",
       "      <td>100.png</td>\n",
       "      <td>V0_C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>1000.png</td>\n",
       "      <td>V4_C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7364</th>\n",
       "      <td>10000.png</td>\n",
       "      <td>V5_C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1001.png</td>\n",
       "      <td>V7_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8378</th>\n",
       "      <td>1002.png</td>\n",
       "      <td>V6_C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>1003.png</td>\n",
       "      <td>V2_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>1004.png</td>\n",
       "      <td>V5_C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9515</th>\n",
       "      <td>1005.png</td>\n",
       "      <td>V9_C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1006.png</td>\n",
       "      <td>V4_C9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>1007.png</td>\n",
       "      <td>V2_C9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>1008.png</td>\n",
       "      <td>V4_C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>1009.png</td>\n",
       "      <td>V4_C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>101.png</td>\n",
       "      <td>V4_C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>1010.png</td>\n",
       "      <td>V7_C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162</th>\n",
       "      <td>1011.png</td>\n",
       "      <td>V8_C9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8930</th>\n",
       "      <td>1012.png</td>\n",
       "      <td>V7_C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>1013.png</td>\n",
       "      <td>V3_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1014.png</td>\n",
       "      <td>V7_C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>1015.png</td>\n",
       "      <td>V8_C9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>1016.png</td>\n",
       "      <td>V3_C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>1017.png</td>\n",
       "      <td>V9_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9259</th>\n",
       "      <td>1018.png</td>\n",
       "      <td>V0_C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9081</th>\n",
       "      <td>1019.png</td>\n",
       "      <td>V4_C9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>102.png</td>\n",
       "      <td>V8_C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>1020.png</td>\n",
       "      <td>V6_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>1021.png</td>\n",
       "      <td>V7_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>1022.png</td>\n",
       "      <td>V6_C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8059</th>\n",
       "      <td>1023.png</td>\n",
       "      <td>V1_C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>9972.png</td>\n",
       "      <td>V5_C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>9973.png</td>\n",
       "      <td>V0_C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9804</th>\n",
       "      <td>9974.png</td>\n",
       "      <td>V9_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>9975.png</td>\n",
       "      <td>V7_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>9976.png</td>\n",
       "      <td>V6_C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>9977.png</td>\n",
       "      <td>V5_C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>9978.png</td>\n",
       "      <td>V7_C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>9979.png</td>\n",
       "      <td>V8_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>998.png</td>\n",
       "      <td>V9_C9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>9980.png</td>\n",
       "      <td>V8_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>9981.png</td>\n",
       "      <td>V9_C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>9982.png</td>\n",
       "      <td>V0_C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>9983.png</td>\n",
       "      <td>V7_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>9984.png</td>\n",
       "      <td>V5_C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>9985.png</td>\n",
       "      <td>V8_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>9986.png</td>\n",
       "      <td>V7_C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>9987.png</td>\n",
       "      <td>V0_C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>9988.png</td>\n",
       "      <td>V9_C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>9989.png</td>\n",
       "      <td>V0_C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>999.png</td>\n",
       "      <td>V9_C9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7284</th>\n",
       "      <td>9990.png</td>\n",
       "      <td>V7_C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9661</th>\n",
       "      <td>9991.png</td>\n",
       "      <td>V8_C9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>9992.png</td>\n",
       "      <td>V3_C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>9993.png</td>\n",
       "      <td>V3_C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>9994.png</td>\n",
       "      <td>V6_C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>9995.png</td>\n",
       "      <td>V9_C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>9996.png</td>\n",
       "      <td>V6_C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>9997.png</td>\n",
       "      <td>V5_C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>9998.png</td>\n",
       "      <td>V2_C9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6541</th>\n",
       "      <td>9999.png</td>\n",
       "      <td>V4_C4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ImageId  Class\n",
       "1297      1.png  V5_C8\n",
       "7929     10.png  V9_C3\n",
       "8865    100.png  V0_C5\n",
       "1749   1000.png  V4_C5\n",
       "7364  10000.png  V5_C4\n",
       "126    1001.png  V7_C6\n",
       "8378   1002.png  V6_C4\n",
       "3369   1003.png  V2_C6\n",
       "3339   1004.png  V5_C2\n",
       "9515   1005.png  V9_C4\n",
       "57     1006.png  V4_C9\n",
       "6938   1007.png  V2_C9\n",
       "1405   1008.png  V4_C4\n",
       "560    1009.png  V4_C4\n",
       "3964    101.png  V4_C1\n",
       "1808   1010.png  V7_C1\n",
       "5162   1011.png  V8_C9\n",
       "8930   1012.png  V7_C2\n",
       "636    1013.png  V3_C6\n",
       "279    1014.png  V7_C8\n",
       "4431   1015.png  V8_C9\n",
       "2446   1016.png  V3_C0\n",
       "3188   1017.png  V9_C6\n",
       "9259   1018.png  V0_C8\n",
       "9081   1019.png  V4_C9\n",
       "1397    102.png  V8_C4\n",
       "6609   1020.png  V6_C6\n",
       "7828   1021.png  V7_C6\n",
       "1390   1022.png  V6_C0\n",
       "8059   1023.png  V1_C0\n",
       "...         ...    ...\n",
       "782    9972.png  V5_C0\n",
       "241    9973.png  V0_C0\n",
       "9804   9974.png  V9_C6\n",
       "1615   9975.png  V7_C6\n",
       "2048   9976.png  V6_C4\n",
       "1779   9977.png  V5_C1\n",
       "927    9978.png  V7_C1\n",
       "5957   9979.png  V8_C6\n",
       "5245    998.png  V9_C9\n",
       "5209   9980.png  V8_C6\n",
       "5309   9981.png  V9_C4\n",
       "3982   9982.png  V0_C4\n",
       "1374   9983.png  V7_C6\n",
       "2911   9984.png  V5_C8\n",
       "4941   9985.png  V8_C6\n",
       "534    9986.png  V7_C8\n",
       "579    9987.png  V0_C0\n",
       "2273   9988.png  V9_C2\n",
       "2489   9989.png  V0_C8\n",
       "3224    999.png  V9_C9\n",
       "7284   9990.png  V7_C3\n",
       "9661   9991.png  V8_C9\n",
       "977    9992.png  V3_C3\n",
       "5649   9993.png  V3_C5\n",
       "3266   9994.png  V6_C8\n",
       "7499   9995.png  V9_C6\n",
       "3494   9996.png  V6_C1\n",
       "6420   9997.png  V5_C8\n",
       "2085   9998.png  V2_C9\n",
       "6541   9999.png  V4_C4\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GPU_PAdhAI_contest_tamil_Image_Classifier.ipynb",
   "provenance": [
    {
     "file_id": "1gwdRRTU87eyQAFauCS1tvMOH-mDiDkUS",
     "timestamp": 1559368166648
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
